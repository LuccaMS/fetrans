{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to import the geracao dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('geracao.csv')\n",
    "del dataset[\"Unnamed: 0\"]\n",
    "print(dataset.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to plot every single data in the dataset to see how it looks like\n",
    "dataset.plot(subplots=True)\n",
    "plt.show()\n",
    "#saving the plot as a image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na cÃ©lula abaixo estamos limpando os dados, excluimos dados que tinham a condutividade tÃ©rmica acima de 500, Ã¡rea acima de 30 e dt/dx maior que -50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos podar o dataset removendo instancias em que o dt/dx Ã© muito grande, maior que -50\n",
    "before = dataset.shape[0]\n",
    "\n",
    "dataset = dataset[dataset.iloc[:,4] > -30]\n",
    "dataset = dataset[dataset.iloc[:,3] < 300]\n",
    "dataset = dataset[dataset.iloc[:,2] < 30]\n",
    "#quantidades de rows que temos no dataset\n",
    "after = dataset.shape[0]\n",
    "print(\"antes: \", before)\n",
    "print(\"depois: \", after)\n",
    "print(\"perda: \", (before - after))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot(subplots=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dataset[[\"tx_transf\", \"area\",\"condutividade\",\"dtdx\"]]\n",
    "target = dataset[\"flx_calor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, x_test, y_train_full, y_test = train_test_split(dados, target, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3,activation=\"relu\", input_shape=[4]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=activation, **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(10, 256),\n",
    "    \"learning_rate\": reciprocal(3e-5, 3e-3),\n",
    "    \"activation\": [\"tanh\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=5,n_jobs=1,cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=5,monitor=\"val_loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = rnd_search_cv.best_estimator_.model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the loss and the validation loss\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average of the loss and the val loss\n",
    "#weighted average\n",
    "loss = hist[\"loss\"]\n",
    "val_loss = hist[\"val_loss\"]\n",
    "average_loss = np.average(loss)\n",
    "average_val_loss = np.average(val_loss)\n",
    "print(\"average loss: \", average_loss)\n",
    "print(\"average val loss: \", average_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the predictions and the actual values\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.flatten()\n",
    "#ploting the predictions and the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(y_pred, color=\"red\", label=\"pred\")\n",
    "plt.plot(y_test.values, color=\"green\", label=\"actual\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a scatter graph of the real values and a line of the predictions\n",
    "plt.scatter(y_test.values[:1000], y_pred[:1000], color=\"red\")\n",
    "plt.plot([0, 1], [0, 1], transform=plt.gca().transAxes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting just the first 100 predictions and values\n",
    "plt.plot(y_pred[:100], color=\"red\", label=\"pred\")\n",
    "plt.plot(y_test.values[:100], color=\"green\", label=\"actual\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the first 10 values\n",
    "for i in range(10):\n",
    "    print(\"pred: \", y_pred[i], \"actual: \", y_test.values[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to check if the loss of the model that we trained now is lower than the model that was saved in the file\n",
    "#we are going to load the model that was saved in the file\n",
    "old_model = keras.models.load_model(\"model.h5\")\n",
    "old_loss = old_model.evaluate(x_test, y_test)\n",
    "#checking if the loss of the model that we trained now is lower than the model that was saved in the file\n",
    "if mse_test < old_loss:\n",
    "    model.save(\"model.h5\")\n",
    "    print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset test.csv\n",
    "dataset_test = pd.read_csv('teste.csv')\n",
    "#setting up the target and the data\n",
    "target = dataset_test[\"flx_calor\"]\n",
    "dados = dataset_test[[\"tx_transf\", \"area\",\"condutividade\",\"dtdx\"]]\n",
    "#scaling the data\n",
    "dados = scaler.transform(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the first 10 predctions and the real values\n",
    "y_pred = model.predict(dados)\n",
    "y_pred = y_pred.flatten()\n",
    "for i in range(10):\n",
    "    print(\"pred: \", y_pred[i], \"actual: \", target.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the predictions and the real values\n",
    "plt.plot(y_pred, color=\"red\", label=\"pred\")\n",
    "plt.plot(target.values, color=\"green\", label=\"actual\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25546758498eb315c698ae46b8c183107105e42ace0db9597b3bc8e5bf61efb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
